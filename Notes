Metrics
  1. AUC: use average of standardise rank
          donâ€™t need all raws as looking for rank especially if a category is not present in test  


Feature engineering for time series:

  2. type: count, cumcount (NA with mean), time delta (replace NA with max) 
  3. Groupby, count,... :see TalkingData kernels for pandas possibilities
  4. Time delta: be careful of timing test / train: readjust calculation of features to a day window if too many NAs
  5. keep an eye on duplicates for patterns (imagine how dataset was build)
  6. feat selection: personally trusted a lot on how LightGBM prioritises features, and I operate in the following principles:
      whenever a batch of features improve local validation score, keep them
      whenever a batch of feature decrease score - I will remove the most import features among this batch according to LightGBM, and re-test
      whenever features were not used by LightGBM at all i.e. 0 importance score I will drop them.

  
Large Datasets Tools:
1. Dask: pandas based
2. Big Query: Google SQL (fast!)
3. memo

Models:
1. NN:
  use binary file to load 
  use time delta if not rnn friendly
  use rnn with batch of 1
2. Trees:
  Try Dart (drop out) instead of traditional gbtree


  
